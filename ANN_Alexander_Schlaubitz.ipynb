{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5577f6",
   "metadata": {},
   "source": [
    "### ANN with binary data - sentiment and stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d63253e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca3f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa197a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('LSTM_binary_170621.xlsx', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e94d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('publication_date', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7856f68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44257</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44257</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44201</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42710</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44174</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42580</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44041</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44041</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44041</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42886</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>662 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0  1\n",
       "publication_date      \n",
       "44257             0  1\n",
       "44257             0  1\n",
       "44201             1  0\n",
       "42710             1  0\n",
       "44174             0  1\n",
       "...              .. ..\n",
       "42580             0  1\n",
       "44041             0  0\n",
       "44041             0  1\n",
       "44041             0  1\n",
       "42886             1  0\n",
       "\n",
       "[662 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dummy sentiment variables\n",
    "dummies = pd.get_dummies(df.sentiment, drop_first = True)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ecd239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_ticker</th>\n",
       "      <th>market_cap_mio_chf</th>\n",
       "      <th>mid_or_small</th>\n",
       "      <th>document_name</th>\n",
       "      <th>document_type</th>\n",
       "      <th>source</th>\n",
       "      <th>original_text</th>\n",
       "      <th>flesch_score</th>\n",
       "      <th>wiener_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>t-13</th>\n",
       "      <th>t-14</th>\n",
       "      <th>t-15</th>\n",
       "      <th>t-16</th>\n",
       "      <th>t-17</th>\n",
       "      <th>t-18</th>\n",
       "      <th>t-19</th>\n",
       "      <th>t-20</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44257</th>\n",
       "      <td>ARBN</td>\n",
       "      <td>1198</td>\n",
       "      <td>small_cap</td>\n",
       "      <td>ARBN_02.03.2021.txt</td>\n",
       "      <td>news</td>\n",
       "      <td>cash.ch</td>\n",
       "      <td>Der Bauzulieferer Arbonia hat im vergangenen G...</td>\n",
       "      <td>43.880769</td>\n",
       "      <td>11.839886</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44257</th>\n",
       "      <td>ARBN</td>\n",
       "      <td>1198</td>\n",
       "      <td>small_cap</td>\n",
       "      <td>ARBN_02.03.2021_2.txt</td>\n",
       "      <td>news</td>\n",
       "      <td>cash.ch</td>\n",
       "      <td>Die Aktien von Arbonia legen am Dienstag klar ...</td>\n",
       "      <td>48.471429</td>\n",
       "      <td>10.630978</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44201</th>\n",
       "      <td>ARBN</td>\n",
       "      <td>1198</td>\n",
       "      <td>small_cap</td>\n",
       "      <td>ARBN_05.01.2021.txt</td>\n",
       "      <td>news</td>\n",
       "      <td>cash.ch</td>\n",
       "      <td>Der Verkauf des Fenstergeschäfts hat der Arbon...</td>\n",
       "      <td>30.957143</td>\n",
       "      <td>13.276634</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42710</th>\n",
       "      <td>ARBN</td>\n",
       "      <td>1198</td>\n",
       "      <td>small_cap</td>\n",
       "      <td>ARBN_06.12.2016.txt</td>\n",
       "      <td>news</td>\n",
       "      <td>cash.ch</td>\n",
       "      <td>Der Bauzulieferer AFG Arbonia Forster hat im R...</td>\n",
       "      <td>39.566667</td>\n",
       "      <td>16.064963</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44174</th>\n",
       "      <td>ARBN</td>\n",
       "      <td>1198</td>\n",
       "      <td>small_cap</td>\n",
       "      <td>ARBN_09.12.2020.txt</td>\n",
       "      <td>news</td>\n",
       "      <td>cash.ch</td>\n",
       "      <td>Beim Bauausrüster Arbonia hat sich im zweiten ...</td>\n",
       "      <td>53.879167</td>\n",
       "      <td>10.673042</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42580</th>\n",
       "      <td>ZEHN</td>\n",
       "      <td>972</td>\n",
       "      <td>small_cap</td>\n",
       "      <td>zehn_29.07.2016.txt</td>\n",
       "      <td>quarterly_earnings_report</td>\n",
       "      <td>company</td>\n",
       "      <td>Umsatzsteigerung und Ergebnisverbesserung. Die...</td>\n",
       "      <td>46.597119</td>\n",
       "      <td>11.132120</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44041</th>\n",
       "      <td>ZEHN</td>\n",
       "      <td>972</td>\n",
       "      <td>small_cap</td>\n",
       "      <td>ZEHN_29.07.2020 (2).txt</td>\n",
       "      <td>news</td>\n",
       "      <td>cash.ch</td>\n",
       "      <td>Zehnder übertrifft Erwartungen deutlich. Die a...</td>\n",
       "      <td>58.866667</td>\n",
       "      <td>9.486783</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44041</th>\n",
       "      <td>ZEHN</td>\n",
       "      <td>972</td>\n",
       "      <td>small_cap</td>\n",
       "      <td>ZEHN_29.07.2020.txt</td>\n",
       "      <td>news</td>\n",
       "      <td>cash.ch</td>\n",
       "      <td>Zehnder-Aktien legen kräftig zu - Halbjahresza...</td>\n",
       "      <td>38.060164</td>\n",
       "      <td>12.875756</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44041</th>\n",
       "      <td>ZEHN</td>\n",
       "      <td>972</td>\n",
       "      <td>small_cap</td>\n",
       "      <td>zehn_29.07.2020.txt1</td>\n",
       "      <td>quarterly_earnings_report</td>\n",
       "      <td>company</td>\n",
       "      <td>Umsatzrückgang – EBIT leicht gesteigert. Der U...</td>\n",
       "      <td>49.735000</td>\n",
       "      <td>8.926577</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42886</th>\n",
       "      <td>ZEHN</td>\n",
       "      <td>972</td>\n",
       "      <td>small_cap</td>\n",
       "      <td>ZEHN_31.05.2017.txt</td>\n",
       "      <td>news</td>\n",
       "      <td>cash.ch</td>\n",
       "      <td>Zehnder unterbricht Produktion am Standort Man...</td>\n",
       "      <td>60.630000</td>\n",
       "      <td>9.252483</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>662 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 company_ticker  market_cap_mio_chf mid_or_small  \\\n",
       "publication_date                                                   \n",
       "44257                      ARBN                1198    small_cap   \n",
       "44257                      ARBN                1198    small_cap   \n",
       "44201                      ARBN                1198    small_cap   \n",
       "42710                      ARBN                1198    small_cap   \n",
       "44174                      ARBN                1198    small_cap   \n",
       "...                         ...                 ...          ...   \n",
       "42580                      ZEHN                 972    small_cap   \n",
       "44041                      ZEHN                 972    small_cap   \n",
       "44041                      ZEHN                 972    small_cap   \n",
       "44041                      ZEHN                 972    small_cap   \n",
       "42886                      ZEHN                 972    small_cap   \n",
       "\n",
       "                            document_name              document_type   source  \\\n",
       "publication_date                                                                \n",
       "44257                 ARBN_02.03.2021.txt                       news  cash.ch   \n",
       "44257               ARBN_02.03.2021_2.txt                       news  cash.ch   \n",
       "44201                 ARBN_05.01.2021.txt                       news  cash.ch   \n",
       "42710                 ARBN_06.12.2016.txt                       news  cash.ch   \n",
       "44174                 ARBN_09.12.2020.txt                       news  cash.ch   \n",
       "...                                   ...                        ...      ...   \n",
       "42580                 zehn_29.07.2016.txt  quarterly_earnings_report  company   \n",
       "44041             ZEHN_29.07.2020 (2).txt                       news  cash.ch   \n",
       "44041                 ZEHN_29.07.2020.txt                       news  cash.ch   \n",
       "44041                zehn_29.07.2020.txt1  quarterly_earnings_report  company   \n",
       "42886                 ZEHN_31.05.2017.txt                       news  cash.ch   \n",
       "\n",
       "                                                      original_text  \\\n",
       "publication_date                                                      \n",
       "44257             Der Bauzulieferer Arbonia hat im vergangenen G...   \n",
       "44257             Die Aktien von Arbonia legen am Dienstag klar ...   \n",
       "44201             Der Verkauf des Fenstergeschäfts hat der Arbon...   \n",
       "42710             Der Bauzulieferer AFG Arbonia Forster hat im R...   \n",
       "44174             Beim Bauausrüster Arbonia hat sich im zweiten ...   \n",
       "...                                                             ...   \n",
       "42580             Umsatzsteigerung und Ergebnisverbesserung. Die...   \n",
       "44041             Zehnder übertrifft Erwartungen deutlich. Die a...   \n",
       "44041             Zehnder-Aktien legen kräftig zu - Halbjahresza...   \n",
       "44041             Umsatzrückgang – EBIT leicht gesteigert. Der U...   \n",
       "42886             Zehnder unterbricht Produktion am Standort Man...   \n",
       "\n",
       "                  flesch_score  wiener_score  sentiment  ... t-13  t-14  t-15  \\\n",
       "publication_date                                         ...                    \n",
       "44257                43.880769     11.839886          1  ...    1     1    -1   \n",
       "44257                48.471429     10.630978          1  ...    1     1    -1   \n",
       "44201                30.957143     13.276634          0  ...    1     1     1   \n",
       "42710                39.566667     16.064963          0  ...    0     1     1   \n",
       "44174                53.879167     10.673042          1  ...    1     1     1   \n",
       "...                        ...           ...        ...  ...  ...   ...   ...   \n",
       "42580                46.597119     11.132120          1  ...    1     1     1   \n",
       "44041                58.866667      9.486783         -1  ...    1    -1    -1   \n",
       "44041                38.060164     12.875756          1  ...    1    -1    -1   \n",
       "44041                49.735000      8.926577          1  ...    1    -1    -1   \n",
       "42886                60.630000      9.252483          0  ...   -1     1    -1   \n",
       "\n",
       "                  t-16  t-17  t-18  t-19  t-20  0  1  \n",
       "publication_date                                      \n",
       "44257                1    -1     1     1     1  0  1  \n",
       "44257                1    -1     1     1     1  0  1  \n",
       "44201               -1     1     1    -1    -1  1  0  \n",
       "42710                1    -1     1     1    -1  1  0  \n",
       "44174               -1     1     1     1     1  0  1  \n",
       "...                ...   ...   ...   ...   ... .. ..  \n",
       "42580                1    -1    -1    -1     1  0  1  \n",
       "44041                1    -1    -1     1    -1  0  0  \n",
       "44041                1    -1    -1     1    -1  0  1  \n",
       "44041                1    -1    -1     1    -1  0  1  \n",
       "42886                1     1    -1     1     1  1  0  \n",
       "\n",
       "[662 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add dummies to original df\n",
    "df =pd.concat([df,dummies],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffff6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define y variable\n",
    "y = df['t+0']\n",
    "#replace -1 with 0\n",
    "y = y.replace(-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72b50c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df.iloc[:,12:]\n",
    "x2 = df.iloc[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f7f8734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-1</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-10</th>\n",
       "      <th>...</th>\n",
       "      <th>t-13</th>\n",
       "      <th>t-14</th>\n",
       "      <th>t-15</th>\n",
       "      <th>t-16</th>\n",
       "      <th>t-17</th>\n",
       "      <th>t-18</th>\n",
       "      <th>t-19</th>\n",
       "      <th>t-20</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44257</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44257</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44201</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42710</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44174</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  t-1  t-2  t-3  t-4  t-5  t-6  t-7  t-8  t-9  t-10  ...  \\\n",
       "publication_date                                                     ...   \n",
       "44257               1    0    1    1    1    1    1   -1   -1     1  ...   \n",
       "44257               1    0    1    1    1    1    1   -1   -1     1  ...   \n",
       "44201               1    0    1   -1    1   -1   -1    1    0    -1  ...   \n",
       "42710               1   -1    1    1    0   -1    1    1    1    -1  ...   \n",
       "44174              -1    1    1   -1   -1   -1   -1    1    1     0  ...   \n",
       "\n",
       "                  t-13  t-14  t-15  t-16  t-17  t-18  t-19  t-20  0  1  \n",
       "publication_date                                                        \n",
       "44257                1     1    -1     1    -1     1     1     1  0  1  \n",
       "44257                1     1    -1     1    -1     1     1     1  0  1  \n",
       "44201                1     1     1    -1     1     1    -1    -1  1  0  \n",
       "42710                0     1     1     1    -1     1     1    -1  1  0  \n",
       "44174                1     1     1    -1     1     1     1     1  0  1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcd83bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f3313ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(662, 22)\n"
     ]
    }
   ],
   "source": [
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53cf2a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  0,  1, ...,  1,  0,  1]],\n",
       "\n",
       "       [[ 1,  0,  1, ...,  1,  0,  1]],\n",
       "\n",
       "       [[ 1,  0,  1, ..., -1,  1,  0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1, -1, -1, ..., -1,  0,  1]],\n",
       "\n",
       "       [[-1, -1, -1, ..., -1,  0,  1]],\n",
       "\n",
       "       [[-1,  1,  1, ...,  1,  1,  0]]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.reshape(662, 1, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a42f9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y as np array\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d022ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x1, y, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9bf942b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.23156014, -1.03697099, -0.92756813, ..., -1.04041871,\n",
       "        -0.66594163, -1.27864015],\n",
       "       [ 0.85455193,  0.98817235, -0.92756813, ..., -1.04041871,\n",
       "         1.5016331 , -1.27864015],\n",
       "       [-1.23156014,  0.98817235, -0.92756813, ..., -1.04041871,\n",
       "        -0.66594163,  0.78208087],\n",
       "       ...,\n",
       "       [ 0.85455193,  0.98817235, -0.92756813, ...,  1.00348077,\n",
       "         1.5016331 , -1.27864015],\n",
       "       [ 0.85455193,  0.98817235,  1.11185318, ..., -1.04041871,\n",
       "        -0.66594163,  0.78208087],\n",
       "       [ 0.85455193,  0.98817235, -0.92756813, ...,  1.00348077,\n",
       "        -0.66594163,  0.78208087]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "training_set_scaled = sc.fit_transform(X_train)\n",
    "\n",
    "sc_predict = StandardScaler()\n",
    "sc_predict.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e4c612c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dff05a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af7ff3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and packages from Keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Initializing the Neural Network \n",
    "model = Sequential([\n",
    "    tf.keras.layers.Dense(22, input_shape = (X_train.shape[1],)),#only indicate nr. of columns\n",
    "    \n",
    "    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "\n",
    "# Compiling the Neural Network\n",
    "model.compile(optimizer = Adam(learning_rate=0.01), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bd072f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.7703 - accuracy: 0.5101 - val_loss: 1.2009 - val_accuracy: 0.4200\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9237 - accuracy: 0.4722 - val_loss: 0.7149 - val_accuracy: 0.5700\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6906 - accuracy: 0.5783 - val_loss: 0.7196 - val_accuracy: 0.5700\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6749 - accuracy: 0.5884 - val_loss: 0.6723 - val_accuracy: 0.5700\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6448 - accuracy: 0.6566 - val_loss: 0.6747 - val_accuracy: 0.5600\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6366 - accuracy: 0.6439 - val_loss: 0.6850 - val_accuracy: 0.5900\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6152 - accuracy: 0.6843 - val_loss: 0.6904 - val_accuracy: 0.6000\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5956 - accuracy: 0.6641 - val_loss: 0.7001 - val_accuracy: 0.6200\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5727 - accuracy: 0.6894 - val_loss: 0.7141 - val_accuracy: 0.6300\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5387 - accuracy: 0.7121 - val_loss: 0.7177 - val_accuracy: 0.6200\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5074 - accuracy: 0.7071 - val_loss: 0.7220 - val_accuracy: 0.6400\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4907 - accuracy: 0.7525 - val_loss: 0.7251 - val_accuracy: 0.6400\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4631 - accuracy: 0.7828 - val_loss: 0.7460 - val_accuracy: 0.6400\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4352 - accuracy: 0.7955 - val_loss: 0.7596 - val_accuracy: 0.6500\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4169 - accuracy: 0.8131 - val_loss: 0.7613 - val_accuracy: 0.6500\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3893 - accuracy: 0.8333 - val_loss: 0.7808 - val_accuracy: 0.6900\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3804 - accuracy: 0.8182 - val_loss: 0.7890 - val_accuracy: 0.6900\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3455 - accuracy: 0.8384 - val_loss: 0.7770 - val_accuracy: 0.7000\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3306 - accuracy: 0.8384 - val_loss: 0.7757 - val_accuracy: 0.7000\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3009 - accuracy: 0.8460 - val_loss: 0.7887 - val_accuracy: 0.7700\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2878 - accuracy: 0.8712 - val_loss: 0.8063 - val_accuracy: 0.7700\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2847 - accuracy: 0.8586 - val_loss: 0.7910 - val_accuracy: 0.7800\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2846 - accuracy: 0.8788 - val_loss: 0.8657 - val_accuracy: 0.7700\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2616 - accuracy: 0.8939 - val_loss: 0.9786 - val_accuracy: 0.7200\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2339 - accuracy: 0.9015 - val_loss: 0.9024 - val_accuracy: 0.7500\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2141 - accuracy: 0.9091 - val_loss: 0.8901 - val_accuracy: 0.7800\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1906 - accuracy: 0.9116 - val_loss: 0.9014 - val_accuracy: 0.7500\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2004 - accuracy: 0.9268 - val_loss: 0.8852 - val_accuracy: 0.7800\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2083 - accuracy: 0.9192 - val_loss: 0.9672 - val_accuracy: 0.7700\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1638 - accuracy: 0.9293 - val_loss: 1.0185 - val_accuracy: 0.7200\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1777 - accuracy: 0.9217 - val_loss: 0.9399 - val_accuracy: 0.7500\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1728 - accuracy: 0.9444 - val_loss: 0.8898 - val_accuracy: 0.7300\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2047 - accuracy: 0.9141 - val_loss: 0.8531 - val_accuracy: 0.7500\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1450 - accuracy: 0.9470 - val_loss: 0.9090 - val_accuracy: 0.7600\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1724 - accuracy: 0.9217 - val_loss: 1.0424 - val_accuracy: 0.7900\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2118 - accuracy: 0.9217 - val_loss: 0.9667 - val_accuracy: 0.7900\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1381 - accuracy: 0.9343 - val_loss: 0.8675 - val_accuracy: 0.7800\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1430 - accuracy: 0.9495 - val_loss: 0.8362 - val_accuracy: 0.7800\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1516 - accuracy: 0.9470 - val_loss: 0.9349 - val_accuracy: 0.7300\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1313 - accuracy: 0.9646 - val_loss: 1.1217 - val_accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1764 - accuracy: 0.9369 - val_loss: 1.2183 - val_accuracy: 0.7600\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1274 - accuracy: 0.9444 - val_loss: 1.3472 - val_accuracy: 0.7400\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1737 - accuracy: 0.9470 - val_loss: 1.3918 - val_accuracy: 0.7300\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1667 - accuracy: 0.9419 - val_loss: 1.2913 - val_accuracy: 0.7200\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1543 - accuracy: 0.95 - 0s 10ms/step - loss: 0.1622 - accuracy: 0.9520 - val_loss: 1.1012 - val_accuracy: 0.7400\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1353 - accuracy: 0.9545 - val_loss: 0.9672 - val_accuracy: 0.7800\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1241 - accuracy: 0.9470 - val_loss: 0.9343 - val_accuracy: 0.7600\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1591 - accuracy: 0.9318 - val_loss: 0.9517 - val_accuracy: 0.7700\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1166 - accuracy: 0.9545 - val_loss: 0.9802 - val_accuracy: 0.7600\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1358 - accuracy: 0.9621 - val_loss: 0.9758 - val_accuracy: 0.7500\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1349 - accuracy: 0.9495 - val_loss: 0.9645 - val_accuracy: 0.7600\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1338 - accuracy: 0.9495 - val_loss: 1.0271 - val_accuracy: 0.7800\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1248 - accuracy: 0.9470 - val_loss: 1.0962 - val_accuracy: 0.7500\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1132 - accuracy: 0.9571 - val_loss: 1.1485 - val_accuracy: 0.7500\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0947 - accuracy: 0.9571 - val_loss: 1.1678 - val_accuracy: 0.7600\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0820 - accuracy: 0.9747 - val_loss: 1.2446 - val_accuracy: 0.7300\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0993 - accuracy: 0.9646 - val_loss: 1.1927 - val_accuracy: 0.7700\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0959 - accuracy: 0.9621 - val_loss: 1.1417 - val_accuracy: 0.7600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0828 - accuracy: 0.9773 - val_loss: 1.2023 - val_accuracy: 0.7700\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0702 - accuracy: 0.9747 - val_loss: 1.2233 - val_accuracy: 0.7700\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0757 - accuracy: 0.9646 - val_loss: 1.1711 - val_accuracy: 0.7700\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1226 - accuracy: 0.9571 - val_loss: 1.1716 - val_accuracy: 0.7300\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0692 - accuracy: 0.9848 - val_loss: 1.1668 - val_accuracy: 0.7400\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0526 - accuracy: 0.9823 - val_loss: 1.1224 - val_accuracy: 0.7700\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0803 - accuracy: 0.9722 - val_loss: 1.1513 - val_accuracy: 0.7600\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0726 - accuracy: 0.9722 - val_loss: 1.1720 - val_accuracy: 0.7600\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1007 - accuracy: 0.9672 - val_loss: 1.3324 - val_accuracy: 0.7600\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0543 - accuracy: 0.9798 - val_loss: 1.6298 - val_accuracy: 0.7700\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0734 - accuracy: 0.9722 - val_loss: 1.7144 - val_accuracy: 0.7600\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0498 - accuracy: 0.9747 - val_loss: 1.6974 - val_accuracy: 0.7700\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0504 - accuracy: 0.9823 - val_loss: 1.6383 - val_accuracy: 0.7600\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0665 - accuracy: 0.9697 - val_loss: 1.5390 - val_accuracy: 0.7600\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0455 - accuracy: 0.9773 - val_loss: 1.4863 - val_accuracy: 0.7900\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0591 - accuracy: 0.9823 - val_loss: 1.4634 - val_accuracy: 0.7800\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0390 - accuracy: 0.9848 - val_loss: 1.4863 - val_accuracy: 0.7900\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0375 - accuracy: 0.9848 - val_loss: 1.5093 - val_accuracy: 0.8000\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0834 - accuracy: 0.9697 - val_loss: 1.4920 - val_accuracy: 0.7700\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0404 - accuracy: 0.9899 - val_loss: 1.5138 - val_accuracy: 0.7800\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0517 - accuracy: 0.9823 - val_loss: 1.5111 - val_accuracy: 0.7700\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.9874 - val_loss: 1.5431 - val_accuracy: 0.7700\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0621 - accuracy: 0.9848 - val_loss: 1.5757 - val_accuracy: 0.7700\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0382 - accuracy: 0.9899 - val_loss: 1.6689 - val_accuracy: 0.7700\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0458 - accuracy: 0.9773 - val_loss: 1.7654 - val_accuracy: 0.7700\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0429 - accuracy: 0.9773 - val_loss: 1.8734 - val_accuracy: 0.7800\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0584 - accuracy: 0.9823 - val_loss: 1.9206 - val_accuracy: 0.7900\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0463 - accuracy: 0.9823 - val_loss: 1.9420 - val_accuracy: 0.7700\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1144 - accuracy: 0.9646 - val_loss: 1.8026 - val_accuracy: 0.7500\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0609 - accuracy: 0.9874 - val_loss: 1.7058 - val_accuracy: 0.7500\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0718 - accuracy: 0.9722 - val_loss: 1.7458 - val_accuracy: 0.7800\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0426 - accuracy: 0.9848 - val_loss: 1.8594 - val_accuracy: 0.7400\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0446 - accuracy: 0.9848 - val_loss: 1.9238 - val_accuracy: 0.7400\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0563 - accuracy: 0.9722 - val_loss: 1.9135 - val_accuracy: 0.7300\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0444 - accuracy: 0.9899 - val_loss: 1.8696 - val_accuracy: 0.7300\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.9874 - val_loss: 1.8186 - val_accuracy: 0.7400\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 1.8665 - val_accuracy: 0.7500\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.9773 - val_loss: 1.9536 - val_accuracy: 0.7400\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0523 - accuracy: 0.9823 - val_loss: 2.0177 - val_accuracy: 0.7400\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0331 - accuracy: 0.9899 - val_loss: 2.0221 - val_accuracy: 0.7300\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0360 - accuracy: 0.9874 - val_loss: 1.9322 - val_accuracy: 0.7400\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0658 - accuracy: 0.9848 - val_loss: 1.7809 - val_accuracy: 0.7600\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0467 - accuracy: 0.9798 - val_loss: 1.6885 - val_accuracy: 0.7600\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0560 - accuracy: 0.9848 - val_loss: 1.7807 - val_accuracy: 0.7500\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0440 - accuracy: 0.9874 - val_loss: 1.8680 - val_accuracy: 0.7400\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0615 - accuracy: 0.9798 - val_loss: 1.9805 - val_accuracy: 0.7500\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0556 - accuracy: 0.9798 - val_loss: 2.0240 - val_accuracy: 0.7500\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0450 - accuracy: 0.9823 - val_loss: 1.9969 - val_accuracy: 0.7500\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0371 - accuracy: 0.9874 - val_loss: 1.9453 - val_accuracy: 0.7500\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0403 - accuracy: 0.9899 - val_loss: 1.9251 - val_accuracy: 0.7500\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0453 - accuracy: 0.9798 - val_loss: 1.9457 - val_accuracy: 0.7400\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0683 - accuracy: 0.9773 - val_loss: 1.8993 - val_accuracy: 0.7400\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0345 - accuracy: 0.9823 - val_loss: 1.8871 - val_accuracy: 0.7400\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0415 - accuracy: 0.9874 - val_loss: 1.8731 - val_accuracy: 0.7400\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0320 - accuracy: 0.9874 - val_loss: 1.8706 - val_accuracy: 0.7500\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9722 - val_loss: 1.9914 - val_accuracy: 0.7400\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.9773 - val_loss: 2.0845 - val_accuracy: 0.7600\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0555 - accuracy: 0.9823 - val_loss: 1.9402 - val_accuracy: 0.7400\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.9798 - val_loss: 1.9670 - val_accuracy: 0.7700\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0277 - accuracy: 0.9899 - val_loss: 2.1316 - val_accuracy: 0.7800\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0319 - accuracy: 0.9848 - val_loss: 2.1901 - val_accuracy: 0.7700\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0925 - accuracy: 0.9823 - val_loss: 1.9835 - val_accuracy: 0.7700\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0420 - accuracy: 0.9823 - val_loss: 1.9385 - val_accuracy: 0.7500\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0618 - accuracy: 0.9798 - val_loss: 1.8426 - val_accuracy: 0.7600\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0819 - accuracy: 0.9697 - val_loss: 1.8047 - val_accuracy: 0.7500\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0757 - accuracy: 0.9747 - val_loss: 1.8366 - val_accuracy: 0.7700\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0962 - accuracy: 0.9672 - val_loss: 1.7953 - val_accuracy: 0.7700\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9798 - val_loss: 1.7609 - val_accuracy: 0.8000\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0981 - accuracy: 0.9773 - val_loss: 1.7800 - val_accuracy: 0.8100\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0800 - accuracy: 0.9747 - val_loss: 1.7610 - val_accuracy: 0.7900\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0644 - accuracy: 0.9773 - val_loss: 1.7922 - val_accuracy: 0.7800\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0377 - accuracy: 0.9874 - val_loss: 1.8475 - val_accuracy: 0.7800\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0426 - accuracy: 0.9848 - val_loss: 1.9315 - val_accuracy: 0.7600\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0744 - accuracy: 0.9697 - val_loss: 1.8176 - val_accuracy: 0.7400\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0397 - accuracy: 0.9848 - val_loss: 1.7209 - val_accuracy: 0.7600\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0583 - accuracy: 0.9848 - val_loss: 1.7236 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0723 - accuracy: 0.9823 - val_loss: 1.7715 - val_accuracy: 0.7800\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0885 - accuracy: 0.9722 - val_loss: 1.7804 - val_accuracy: 0.7900\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9798 - val_loss: 1.8572 - val_accuracy: 0.7800\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9899 - val_loss: 1.9749 - val_accuracy: 0.7600\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0341 - accuracy: 0.9874 - val_loss: 2.0818 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0331 - accuracy: 0.9823 - val_loss: 2.1790 - val_accuracy: 0.7700\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0767 - accuracy: 0.9697 - val_loss: 2.1313 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0358 - accuracy: 0.9848 - val_loss: 2.0952 - val_accuracy: 0.7400\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0496 - accuracy: 0.9798 - val_loss: 2.0668 - val_accuracy: 0.7500\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0498 - accuracy: 0.9823 - val_loss: 1.9515 - val_accuracy: 0.7600\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0327 - accuracy: 0.9949 - val_loss: 1.7752 - val_accuracy: 0.7500\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1147 - accuracy: 0.9747 - val_loss: 1.7710 - val_accuracy: 0.7600\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.9848 - val_loss: 1.7385 - val_accuracy: 0.7600\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0268 - accuracy: 0.9924 - val_loss: 1.7394 - val_accuracy: 0.7600\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0397 - accuracy: 0.9848 - val_loss: 1.8125 - val_accuracy: 0.7600\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0317 - accuracy: 0.9874 - val_loss: 1.7894 - val_accuracy: 0.7800\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0499 - accuracy: 0.9899 - val_loss: 1.7073 - val_accuracy: 0.7800\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0350 - accuracy: 0.9823 - val_loss: 1.6289 - val_accuracy: 0.8100\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9899 - val_loss: 1.5916 - val_accuracy: 0.7800\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0274 - accuracy: 0.9874 - val_loss: 1.5862 - val_accuracy: 0.7600\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0376 - accuracy: 0.9874 - val_loss: 1.5832 - val_accuracy: 0.7600\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0285 - accuracy: 0.9949 - val_loss: 1.6246 - val_accuracy: 0.7600\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0381 - accuracy: 0.9874 - val_loss: 1.6323 - val_accuracy: 0.7600\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0651 - accuracy: 0.9773 - val_loss: 1.6745 - val_accuracy: 0.7400\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0470 - accuracy: 0.9773 - val_loss: 1.7900 - val_accuracy: 0.7400\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9823 - val_loss: 1.8862 - val_accuracy: 0.7500\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0248 - accuracy: 0.9874 - val_loss: 1.9431 - val_accuracy: 0.7200\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0188 - accuracy: 0.9924 - val_loss: 2.0319 - val_accuracy: 0.7300\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0210 - accuracy: 0.9924 - val_loss: 2.1226 - val_accuracy: 0.7300\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0388 - accuracy: 0.9848 - val_loss: 2.2047 - val_accuracy: 0.7500\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0349 - accuracy: 0.9899 - val_loss: 2.2894 - val_accuracy: 0.7800\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9924 - val_loss: 2.3496 - val_accuracy: 0.7800\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0581 - accuracy: 0.9848 - val_loss: 2.4143 - val_accuracy: 0.7800\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0396 - accuracy: 0.9899 - val_loss: 2.4661 - val_accuracy: 0.7600\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0276 - accuracy: 0.9924 - val_loss: 2.4394 - val_accuracy: 0.7600\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0290 - accuracy: 0.9874 - val_loss: 2.3621 - val_accuracy: 0.7800\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9949 - val_loss: 2.2722 - val_accuracy: 0.7700\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 2.1898 - val_accuracy: 0.7600\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0124 - accuracy: 0.9949 - val_loss: 2.1465 - val_accuracy: 0.7700\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0553 - accuracy: 0.9874 - val_loss: 2.0585 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0246 - accuracy: 0.9899 - val_loss: 2.0694 - val_accuracy: 0.7300\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0190 - accuracy: 0.9975 - val_loss: 2.1684 - val_accuracy: 0.7700\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0167 - accuracy: 0.9975 - val_loss: 2.2300 - val_accuracy: 0.7600\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0112 - accuracy: 0.9975 - val_loss: 2.2493 - val_accuracy: 0.7700\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0112 - accuracy: 0.9924 - val_loss: 2.2765 - val_accuracy: 0.7700\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0439 - accuracy: 0.9823 - val_loss: 2.2392 - val_accuracy: 0.7600\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9899 - val_loss: 2.3245 - val_accuracy: 0.7600\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0327 - accuracy: 0.9848 - val_loss: 2.4797 - val_accuracy: 0.7600\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9823 - val_loss: 2.2792 - val_accuracy: 0.7500\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0195 - accuracy: 0.9924 - val_loss: 2.2530 - val_accuracy: 0.7800\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0399 - accuracy: 0.9823 - val_loss: 2.2841 - val_accuracy: 0.7800\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9798 - val_loss: 2.2776 - val_accuracy: 0.7800\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0776 - accuracy: 0.9773 - val_loss: 2.2590 - val_accuracy: 0.7700\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0275 - accuracy: 0.9924 - val_loss: 2.4759 - val_accuracy: 0.7700\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0583 - accuracy: 0.9848 - val_loss: 2.6228 - val_accuracy: 0.7700\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1434 - accuracy: 0.9621 - val_loss: 2.2765 - val_accuracy: 0.8000\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0838 - accuracy: 0.9798 - val_loss: 2.0596 - val_accuracy: 0.8100\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0662 - accuracy: 0.9848 - val_loss: 1.8528 - val_accuracy: 0.8000\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0530 - accuracy: 0.9823 - val_loss: 1.7175 - val_accuracy: 0.7900\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0498 - accuracy: 0.9798 - val_loss: 1.6915 - val_accuracy: 0.8000\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1221 - accuracy: 0.9672 - val_loss: 1.7770 - val_accuracy: 0.7600\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0507 - accuracy: 0.9798 - val_loss: 1.8419 - val_accuracy: 0.7500\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0302 - accuracy: 0.9848 - val_loss: 1.9131 - val_accuracy: 0.7400\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0451 - accuracy: 0.9823 - val_loss: 1.9789 - val_accuracy: 0.7400\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0775 - accuracy: 0.9747 - val_loss: 1.8739 - val_accuracy: 0.7600\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1053 - accuracy: 0.9621 - val_loss: 1.6807 - val_accuracy: 0.7700\n"
     ]
    }
   ],
   "source": [
    "#train model using 0.2 val split\n",
    "#%%time\n",
    "history = model.fit(X_train, y_train, shuffle=False, epochs=200, validation_split=0.2, verbose=1, batch_size=256, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce82abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 3.9550 - accuracy: 0.7108\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9911ea4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 219]\n",
      " [  1 277]]\n",
      "Accuracy if only prediction ones: 0.5584677419354839\n"
     ]
    }
   ],
   "source": [
    "#count value frequency in y_train\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "print (np.asarray((unique, counts)).T)\n",
    "print('Accuracy if only prediction ones:', (np.asarray((unique, counts)).T)[1][1] / ((np.asarray((unique, counts)).T)[0][1] + (np.asarray((unique, counts)).T)[1][1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a16a13a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 67]\n",
      " [ 1 99]]\n",
      "Accuracy if only prediction ones: 0.5963855421686747\n"
     ]
    }
   ],
   "source": [
    "#count value frequency in y_test and set prediction baseline minimum performance\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "print (np.asarray((unique, counts)).T)\n",
    "print('Accuracy if only prediction ones:', (np.asarray((unique, counts)).T)[1][1] / ((np.asarray((unique, counts)).T)[0][1] + (np.asarray((unique, counts)).T)[1][1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70537fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36dd01ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.40454113e-01],\n",
       "       [9.79506969e-03],\n",
       "       [9.99997377e-01],\n",
       "       [6.60569776e-06],\n",
       "       [2.89005041e-03],\n",
       "       [5.86594606e-10],\n",
       "       [1.40540097e-11],\n",
       "       [3.34382057e-04],\n",
       "       [7.52776861e-04],\n",
       "       [1.00000000e+00],\n",
       "       [8.85810447e-09],\n",
       "       [1.40173733e-02],\n",
       "       [1.00000000e+00],\n",
       "       [3.37299168e-01],\n",
       "       [1.49786472e-04],\n",
       "       [9.99754727e-01],\n",
       "       [1.27938529e-06],\n",
       "       [9.97928858e-01],\n",
       "       [6.00146949e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.76812857e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99144435e-01],\n",
       "       [3.54975462e-04],\n",
       "       [3.31357658e-01],\n",
       "       [7.81309518e-06],\n",
       "       [9.99999404e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [7.42663980e-01],\n",
       "       [2.96562910e-04],\n",
       "       [7.73543119e-03],\n",
       "       [8.64839531e-05],\n",
       "       [3.44479084e-03],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [3.61680984e-04],\n",
       "       [1.36062690e-05],\n",
       "       [9.95972872e-01],\n",
       "       [9.88605618e-01],\n",
       "       [9.97928858e-01],\n",
       "       [1.33676423e-07],\n",
       "       [9.77575660e-01],\n",
       "       [9.99988854e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999762e-01],\n",
       "       [4.00213897e-01],\n",
       "       [9.99863148e-01],\n",
       "       [6.38351594e-07],\n",
       "       [1.00000000e+00],\n",
       "       [6.56293878e-07],\n",
       "       [1.14288926e-03],\n",
       "       [1.00000000e+00],\n",
       "       [1.34646893e-04],\n",
       "       [9.99463201e-01],\n",
       "       [9.99981701e-01],\n",
       "       [9.99908090e-01],\n",
       "       [1.00000000e+00],\n",
       "       [6.26802444e-04],\n",
       "       [9.68574703e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.40037966e-01],\n",
       "       [9.98103857e-01],\n",
       "       [9.97807622e-01],\n",
       "       [9.68574703e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.40540097e-11],\n",
       "       [8.00542235e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99990463e-01],\n",
       "       [1.13328993e-02],\n",
       "       [9.99988317e-01],\n",
       "       [2.94629931e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.99964833e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.87825453e-01],\n",
       "       [6.26802444e-04],\n",
       "       [1.00000000e+00],\n",
       "       [1.67807609e-01],\n",
       "       [4.38206248e-16],\n",
       "       [2.19271988e-06],\n",
       "       [9.99998808e-01],\n",
       "       [9.61668372e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.96851265e-01],\n",
       "       [1.76735818e-02],\n",
       "       [3.77640724e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.78959370e-02],\n",
       "       [1.48296356e-04],\n",
       "       [9.06053117e-08],\n",
       "       [9.99849916e-01],\n",
       "       [8.67925763e-01],\n",
       "       [4.27932854e-08],\n",
       "       [5.23447990e-04],\n",
       "       [1.00000000e+00],\n",
       "       [4.30852473e-01],\n",
       "       [7.48290622e-05],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999762e-01],\n",
       "       [1.21601654e-04],\n",
       "       [9.99999046e-01],\n",
       "       [2.59541243e-01],\n",
       "       [9.40341033e-06],\n",
       "       [6.00146949e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.98462915e-01],\n",
       "       [9.99991775e-01],\n",
       "       [9.96851265e-01],\n",
       "       [3.63443434e-01],\n",
       "       [9.99816298e-01],\n",
       "       [9.96412754e-01],\n",
       "       [9.99997377e-01],\n",
       "       [1.10394545e-07],\n",
       "       [9.99997258e-01],\n",
       "       [9.96851265e-01],\n",
       "       [1.32905557e-17],\n",
       "       [3.35752964e-04],\n",
       "       [5.49721181e-01],\n",
       "       [1.00318491e-02],\n",
       "       [1.11803412e-03],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999166e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.83126521e-01],\n",
       "       [9.99997377e-01],\n",
       "       [6.93112612e-04],\n",
       "       [1.10085389e-12],\n",
       "       [1.00000000e+00],\n",
       "       [9.99452293e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.59853518e-01],\n",
       "       [9.50303614e-01],\n",
       "       [7.01656555e-09],\n",
       "       [6.49940968e-03],\n",
       "       [9.98892188e-01],\n",
       "       [9.99984980e-01],\n",
       "       [9.99959826e-01],\n",
       "       [1.21822177e-06],\n",
       "       [9.99999404e-01],\n",
       "       [9.99996424e-01],\n",
       "       [2.71165300e-06],\n",
       "       [2.69177860e-07],\n",
       "       [9.99994099e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [4.35441732e-04],\n",
       "       [1.00000000e+00],\n",
       "       [4.24766898e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.97054935e-01],\n",
       "       [1.41407930e-09],\n",
       "       [1.00000000e+00],\n",
       "       [1.14723742e-01],\n",
       "       [3.56414318e-02],\n",
       "       [2.10629582e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c019be87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot predictions\n",
    "y_pred_plot = pd.DataFrame(y_pred)\n",
    "y_pred_plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfd0bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define cutoff for predictions at naive 0.5\n",
    "cutoff = (y_pred_plot > 0.50) *1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a4bc4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of: 0.7108433734939759\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_test, cutoff, labels=[0, 1,])\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "\n",
    "print('Accuracy score of:' ,accuracy_score(y_test, cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee5030d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65        67\n",
      "           1       0.77      0.74      0.75        99\n",
      "\n",
      "    accuracy                           0.71       166\n",
      "   macro avg       0.70      0.70      0.70       166\n",
      "weighted avg       0.71      0.71      0.71       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0','1']\n",
    "print(classification_report(y_test, cutoff, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8bef15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4056054838627975"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(y_test, cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee339c32",
   "metadata": {},
   "source": [
    "### Same model with only stock data, no sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf18b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('LSTM_binary_170621.xlsx', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35402101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('publication_date', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8edb745",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['t+0']\n",
    "y = y.replace(-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a1d35b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-1</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-10</th>\n",
       "      <th>t-11</th>\n",
       "      <th>t-12</th>\n",
       "      <th>t-13</th>\n",
       "      <th>t-14</th>\n",
       "      <th>t-15</th>\n",
       "      <th>t-16</th>\n",
       "      <th>t-17</th>\n",
       "      <th>t-18</th>\n",
       "      <th>t-19</th>\n",
       "      <th>t-20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44257</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44257</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44201</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42710</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44174</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  t-1  t-2  t-3  t-4  t-5  t-6  t-7  t-8  t-9  t-10  t-11  \\\n",
       "publication_date                                                            \n",
       "44257               1    0    1    1    1    1    1   -1   -1     1    -1   \n",
       "44257               1    0    1    1    1    1    1   -1   -1     1    -1   \n",
       "44201               1    0    1   -1    1   -1   -1    1    0    -1     1   \n",
       "42710               1   -1    1    1    0   -1    1    1    1    -1     0   \n",
       "44174              -1    1    1   -1   -1   -1   -1    1    1     0    -1   \n",
       "\n",
       "                  t-12  t-13  t-14  t-15  t-16  t-17  t-18  t-19  t-20  \n",
       "publication_date                                                        \n",
       "44257               -1     1     1    -1     1    -1     1     1     1  \n",
       "44257               -1     1     1    -1     1    -1     1     1     1  \n",
       "44201                1     1     1     1    -1     1     1    -1    -1  \n",
       "42710                1     0     1     1     1    -1     1     1    -1  \n",
       "44174                0     1     1     1    -1     1     1     1     1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = df.iloc[:,12:]\n",
    "\n",
    "x1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bccf8881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(662, 20)\n"
     ]
    }
   ],
   "source": [
    "x1 = x1.values\n",
    "\n",
    "\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a39efb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "835802f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x1, y, random_state = 2)\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3cee2b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.23156014, -1.03697099, -0.92756813, ..., -0.17553565,\n",
       "         0.99722638, -1.04041871],\n",
       "       [ 0.85455193,  0.98817235, -0.92756813, ...,  0.86514   ,\n",
       "        -1.0339341 , -1.04041871],\n",
       "       [-1.23156014,  0.98817235, -0.92756813, ...,  0.86514   ,\n",
       "        -1.0339341 , -1.04041871],\n",
       "       ...,\n",
       "       [ 0.85455193,  0.98817235, -0.92756813, ...,  0.86514   ,\n",
       "        -1.0339341 ,  1.00348077],\n",
       "       [ 0.85455193,  0.98817235,  1.11185318, ...,  0.86514   ,\n",
       "        -1.0339341 , -1.04041871],\n",
       "       [ 0.85455193,  0.98817235, -0.92756813, ..., -1.21621131,\n",
       "         0.99722638,  1.00348077]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "training_set_scaled = sc.fit_transform(X_train)\n",
    "\n",
    "sc_predict = StandardScaler()\n",
    "sc_predict.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8a35f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and packages from Keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Initializing the Neural Network based on LSTM\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Dense(20, input_shape = (X_train.shape[1],),kernel_regularizer='l2'),#only indicate nr. of columns\n",
    "    \n",
    "    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "# Output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the Neural Network\n",
    "model.compile(optimizer = Adam(learning_rate=0.01), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3634c5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.9803 - accuracy: 0.4672 - val_loss: 0.8702 - val_accuracy: 0.5800\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8658 - accuracy: 0.5480 - val_loss: 0.8424 - val_accuracy: 0.5800\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8388 - accuracy: 0.5530 - val_loss: 0.8177 - val_accuracy: 0.5800\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8150 - accuracy: 0.5530 - val_loss: 0.7959 - val_accuracy: 0.5800\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7940 - accuracy: 0.5530 - val_loss: 0.7769 - val_accuracy: 0.5800\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7757 - accuracy: 0.5530 - val_loss: 0.7605 - val_accuracy: 0.5800\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7599 - accuracy: 0.5530 - val_loss: 0.7463 - val_accuracy: 0.5800\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7465 - accuracy: 0.5530 - val_loss: 0.7343 - val_accuracy: 0.5800\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7350 - accuracy: 0.5530 - val_loss: 0.7242 - val_accuracy: 0.5800\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7254 - accuracy: 0.5530 - val_loss: 0.7157 - val_accuracy: 0.5800\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7174 - accuracy: 0.5530 - val_loss: 0.7087 - val_accuracy: 0.5800\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7109 - accuracy: 0.5530 - val_loss: 0.7030 - val_accuracy: 0.5800\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7055 - accuracy: 0.5530 - val_loss: 0.6983 - val_accuracy: 0.5800\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7012 - accuracy: 0.5530 - val_loss: 0.6946 - val_accuracy: 0.5800\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6979 - accuracy: 0.5530 - val_loss: 0.6917 - val_accuracy: 0.5800\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6952 - accuracy: 0.5530 - val_loss: 0.6895 - val_accuracy: 0.5800\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5530 - val_loss: 0.6878 - val_accuracy: 0.5800\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6917 - accuracy: 0.5530 - val_loss: 0.6865 - val_accuracy: 0.5800\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6906 - accuracy: 0.5530 - val_loss: 0.6855 - val_accuracy: 0.5800\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6898 - accuracy: 0.5530 - val_loss: 0.6848 - val_accuracy: 0.5800\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6892 - accuracy: 0.5530 - val_loss: 0.6843 - val_accuracy: 0.5800\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6888 - accuracy: 0.5530 - val_loss: 0.6839 - val_accuracy: 0.5800\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6885 - accuracy: 0.5530 - val_loss: 0.6836 - val_accuracy: 0.5800\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6883 - accuracy: 0.5530 - val_loss: 0.6835 - val_accuracy: 0.5800\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6882 - accuracy: 0.5530 - val_loss: 0.6833 - val_accuracy: 0.5800\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6881 - accuracy: 0.5530 - val_loss: 0.6832 - val_accuracy: 0.5800\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6880 - accuracy: 0.5530 - val_loss: 0.6831 - val_accuracy: 0.5800\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6880 - accuracy: 0.5530 - val_loss: 0.6831 - val_accuracy: 0.5800\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6880 - accuracy: 0.5530 - val_loss: 0.6830 - val_accuracy: 0.5800\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6879 - accuracy: 0.5530 - val_loss: 0.6830 - val_accuracy: 0.5800\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6879 - accuracy: 0.5530 - val_loss: 0.6830 - val_accuracy: 0.5800\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6879 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6878 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6878 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6878 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6878 - accuracy: 0.5530 - val_loss: 0.6828 - val_accuracy: 0.5800\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6828 - val_accuracy: 0.5800\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6828 - val_accuracy: 0.5800\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6828 - val_accuracy: 0.5800\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6828 - val_accuracy: 0.5800\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6828 - val_accuracy: 0.5800\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6828 - val_accuracy: 0.5800\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6828 - val_accuracy: 0.5800\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6828 - val_accuracy: 0.5800\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6828 - val_accuracy: 0.5800\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6876 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6876 - accuracy: 0.5530 - val_loss: 0.6831 - val_accuracy: 0.5800\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6832 - val_accuracy: 0.5800\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6863 - accuracy: 0.5556 - val_loss: 0.6880 - val_accuracy: 0.5600\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6833 - accuracy: 0.6035 - val_loss: 0.6831 - val_accuracy: 0.5900\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6660 - accuracy: 0.6591 - val_loss: 0.6669 - val_accuracy: 0.6400\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6511 - accuracy: 0.6970 - val_loss: 0.6705 - val_accuracy: 0.6700\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6402 - accuracy: 0.7247 - val_loss: 0.6770 - val_accuracy: 0.6400\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6324 - accuracy: 0.7475 - val_loss: 0.6730 - val_accuracy: 0.6800\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6187 - accuracy: 0.7475 - val_loss: 0.6677 - val_accuracy: 0.6800\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6070 - accuracy: 0.7551 - val_loss: 0.6585 - val_accuracy: 0.6700\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5967 - accuracy: 0.7702 - val_loss: 0.6468 - val_accuracy: 0.7100\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5968 - accuracy: 0.7576 - val_loss: 0.6582 - val_accuracy: 0.7000\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6022 - accuracy: 0.7500 - val_loss: 0.6819 - val_accuracy: 0.6400\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6098 - accuracy: 0.7348 - val_loss: 0.6701 - val_accuracy: 0.6900\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6270 - accuracy: 0.7197 - val_loss: 0.6745 - val_accuracy: 0.6700\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6329 - accuracy: 0.7197 - val_loss: 0.6595 - val_accuracy: 0.6700\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6186 - accuracy: 0.7197 - val_loss: 0.6546 - val_accuracy: 0.6700\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6240 - accuracy: 0.7247 - val_loss: 0.6916 - val_accuracy: 0.6600\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6144 - accuracy: 0.7348 - val_loss: 0.6896 - val_accuracy: 0.6500\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6257 - accuracy: 0.7247 - val_loss: 0.7003 - val_accuracy: 0.6200\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6396 - accuracy: 0.7020 - val_loss: 0.7023 - val_accuracy: 0.6300\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6224 - accuracy: 0.7222 - val_loss: 0.7036 - val_accuracy: 0.6400\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6293 - accuracy: 0.7197 - val_loss: 0.7197 - val_accuracy: 0.6200\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6240 - accuracy: 0.7222 - val_loss: 0.6947 - val_accuracy: 0.6400\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6412 - accuracy: 0.7071 - val_loss: 0.6828 - val_accuracy: 0.6700\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6252 - accuracy: 0.7222 - val_loss: 0.7039 - val_accuracy: 0.6300\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6342 - accuracy: 0.7121 - val_loss: 0.6834 - val_accuracy: 0.6500\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6310 - accuracy: 0.7096 - val_loss: 0.6705 - val_accuracy: 0.6700\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6193 - accuracy: 0.7273 - val_loss: 0.6631 - val_accuracy: 0.6900\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6362 - accuracy: 0.7071 - val_loss: 0.6640 - val_accuracy: 0.6800\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6380 - accuracy: 0.7020 - val_loss: 0.7247 - val_accuracy: 0.6200\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6355 - accuracy: 0.7172 - val_loss: 0.7506 - val_accuracy: 0.6000\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6463 - accuracy: 0.6995 - val_loss: 0.7559 - val_accuracy: 0.5900\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6552 - accuracy: 0.6919 - val_loss: 0.7497 - val_accuracy: 0.6000\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6416 - accuracy: 0.7096 - val_loss: 0.7298 - val_accuracy: 0.6200\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6532 - accuracy: 0.6995 - val_loss: 0.7145 - val_accuracy: 0.6400\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6370 - accuracy: 0.7172 - val_loss: 0.7184 - val_accuracy: 0.6400\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6442 - accuracy: 0.7045 - val_loss: 0.7206 - val_accuracy: 0.6300\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6361 - accuracy: 0.7172 - val_loss: 0.7255 - val_accuracy: 0.6200\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6399 - accuracy: 0.7096 - val_loss: 0.7266 - val_accuracy: 0.6200\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6473 - accuracy: 0.6970 - val_loss: 0.7341 - val_accuracy: 0.6100\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6479 - accuracy: 0.7020 - val_loss: 0.7434 - val_accuracy: 0.6000\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6461 - accuracy: 0.6995 - val_loss: 0.7368 - val_accuracy: 0.6100\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6460 - accuracy: 0.6970 - val_loss: 0.7345 - val_accuracy: 0.6100\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6320 - accuracy: 0.7146 - val_loss: 0.7509 - val_accuracy: 0.5900\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6562 - accuracy: 0.6894 - val_loss: 0.7597 - val_accuracy: 0.5900\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6616 - accuracy: 0.6843 - val_loss: 0.7497 - val_accuracy: 0.6000\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6553 - accuracy: 0.6894 - val_loss: 0.7236 - val_accuracy: 0.6200\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6463 - accuracy: 0.7020 - val_loss: 0.7262 - val_accuracy: 0.6200\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6435 - accuracy: 0.6995 - val_loss: 0.7265 - val_accuracy: 0.6200\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6395 - accuracy: 0.7045 - val_loss: 0.7409 - val_accuracy: 0.6100\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6288 - accuracy: 0.7222 - val_loss: 0.7575 - val_accuracy: 0.5900\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6337 - accuracy: 0.7146 - val_loss: 0.7420 - val_accuracy: 0.6200\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6345 - accuracy: 0.7197 - val_loss: 0.7312 - val_accuracy: 0.6300\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6225 - accuracy: 0.7273 - val_loss: 0.7264 - val_accuracy: 0.6300\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6304 - accuracy: 0.7146 - val_loss: 0.7432 - val_accuracy: 0.6200\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6117 - accuracy: 0.7399 - val_loss: 0.7747 - val_accuracy: 0.6000\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6298 - accuracy: 0.7197 - val_loss: 0.7840 - val_accuracy: 0.5800\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6420 - accuracy: 0.7071 - val_loss: 0.7795 - val_accuracy: 0.5900\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6427 - accuracy: 0.7071 - val_loss: 0.7854 - val_accuracy: 0.5800\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6427 - accuracy: 0.7071 - val_loss: 0.7630 - val_accuracy: 0.6000\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6501 - accuracy: 0.6995 - val_loss: 0.7497 - val_accuracy: 0.6200\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6466 - accuracy: 0.6995 - val_loss: 0.7448 - val_accuracy: 0.6200\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6597 - accuracy: 0.6919 - val_loss: 0.7561 - val_accuracy: 0.6100\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6430 - accuracy: 0.6995 - val_loss: 0.7495 - val_accuracy: 0.6100\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6401 - accuracy: 0.7071 - val_loss: 0.7503 - val_accuracy: 0.6100\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6556 - accuracy: 0.6894 - val_loss: 0.7486 - val_accuracy: 0.6100\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6440 - accuracy: 0.6944 - val_loss: 0.7688 - val_accuracy: 0.5900\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6469 - accuracy: 0.6919 - val_loss: 0.7776 - val_accuracy: 0.5900\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6482 - accuracy: 0.6970 - val_loss: 0.7818 - val_accuracy: 0.5900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6346 - accuracy: 0.7071 - val_loss: 0.7802 - val_accuracy: 0.5900\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6521 - accuracy: 0.6970 - val_loss: 0.7862 - val_accuracy: 0.5800\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6276 - accuracy: 0.7071 - val_loss: 0.8017 - val_accuracy: 0.5700\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6174 - accuracy: 0.7222 - val_loss: 0.7658 - val_accuracy: 0.6000\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6211 - accuracy: 0.7172 - val_loss: 0.7694 - val_accuracy: 0.5900\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6228 - accuracy: 0.7146 - val_loss: 0.7834 - val_accuracy: 0.5700\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6330 - accuracy: 0.7071 - val_loss: 0.7497 - val_accuracy: 0.6100\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6198 - accuracy: 0.7222 - val_loss: 0.7737 - val_accuracy: 0.6000\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6272 - accuracy: 0.7222 - val_loss: 0.7938 - val_accuracy: 0.5900\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6434 - accuracy: 0.7146 - val_loss: 0.7870 - val_accuracy: 0.5900\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6465 - accuracy: 0.7146 - val_loss: 0.8063 - val_accuracy: 0.5700\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6343 - accuracy: 0.7197 - val_loss: 0.8157 - val_accuracy: 0.5600\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6321 - accuracy: 0.7222 - val_loss: 0.8005 - val_accuracy: 0.5700\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6256 - accuracy: 0.7247 - val_loss: 0.8312 - val_accuracy: 0.5500\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6407 - accuracy: 0.7071 - val_loss: 0.8094 - val_accuracy: 0.5700\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6460 - accuracy: 0.6995 - val_loss: 0.7812 - val_accuracy: 0.5800\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6571 - accuracy: 0.6843 - val_loss: 0.7825 - val_accuracy: 0.5900\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6617 - accuracy: 0.6793 - val_loss: 0.7682 - val_accuracy: 0.6000\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6731 - accuracy: 0.6641 - val_loss: 0.7278 - val_accuracy: 0.6300\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6564 - accuracy: 0.6818 - val_loss: 0.7125 - val_accuracy: 0.6400\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6753 - accuracy: 0.6641 - val_loss: 0.7036 - val_accuracy: 0.6400\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6700 - accuracy: 0.6667 - val_loss: 0.6810 - val_accuracy: 0.6600\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6605 - accuracy: 0.6793 - val_loss: 0.6792 - val_accuracy: 0.6600\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6588 - accuracy: 0.6793 - val_loss: 0.6934 - val_accuracy: 0.6500\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6747 - accuracy: 0.6591 - val_loss: 0.6993 - val_accuracy: 0.6400\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6674 - accuracy: 0.6692 - val_loss: 0.7247 - val_accuracy: 0.6300\n",
      "Wall time: 7.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(X_train, y_train, shuffle=False, epochs=200, validation_split=0.2, verbose=1, batch_size=256, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef04d154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7292 - accuracy: 0.6325\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0bf3b7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 219]\n",
      " [  1 277]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21f00d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 67]\n",
      " [ 1 99]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eff97ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11901408],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.631917  ],\n",
       "       [0.11901408],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.11913627],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.11901408],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.63217604],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.11901408],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.55886924],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.63217604],\n",
       "       [0.6270301 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.11901408],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.11901408],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.11901408],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.11901408],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.1191974 ],\n",
       "       [0.11901408],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.11901408],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.12093458],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.11901408],\n",
       "       [0.6321761 ],\n",
       "       [0.11901408],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.11901408],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.63217604],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ],\n",
       "       [0.6321761 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test))\n",
    "#model only predicts 1s\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcd77368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATGUlEQVR4nO3dfWxd933f8fdn1pIqZv1ULawgu6Xbqg+2lRQx67XJVpBws7hJELlYgir1WnnzILTN0mxQsMor0PwxGPOweVuB1CiEOIiwBGZdx6m1KMlqqGONoXESKbUjP8Sx17iuZFdaGlspPcOp3O/+4I1yQ5PhfSIp/vh+AQLvOb/fOef79bU+9/Dce49SVUiS2vL31roASdLoGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7tIQklyT5RJIXkvxFkl9a65qkXm1a6wKkc9jvAt8ExoGfBA4leaiqHlnTqqQexG+oSq+U5HzgOeCqqvpKZ91/B05U1b41LU7qgZdlpMX9KPDyt4K94yHgyjWqR+qL4S4tbgw4vWDdaeB716AWqW+Gu7S4OeCCBesuAP5mDWqR+ma4S4v7CrApyfauda8HfDNV64JvqEpLSDIDFPAvmf+0zKeAN/ppGa0HnrlLS/t1YDNwCrgT+DWDXeuFZ+6S1CDP3CWpQYa7JDXIcJekBhnuktSgc+LGYVu2bKmJiYmzyy+88ALnn3/+2hW0yjZSv/baro3U77nS69GjR79WVf9gsbFzItwnJiY4cuTI2eXZ2VmmpqbWrqBVtpH6tdd2baR+z5Vek/zFUmNelpGkBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAadE99QlaS1NLHvUF/z9+44w419brOUp25920j2s5Bn7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGLRvuST6c5FSShxcZe3+SSrKla93NSZ5M8niSt4y6YEnS8no5c/8IcN3ClUkuA94MPN217gpgF3BlZ5vbk5w3kkolST1bNtyr6n7g64sM/Vfg3wLVtW4nMFNVL1XVV4EngWtGUagkqXcD3VsmyTuAE1X1UJLuoW3AA13LxzvrFtvHHmAPwPj4OLOzs2fH5ubmvmO5dRupX3tt13rud++OM33NH9/c/zZLWan/Zn2He5LXAL8F/JPFhhdZV4uso6r2A/sBJicna2pq6uzY7Ows3cut20j92mu71nO//d4EbO+OM9x2bDT3XXzqhqmR7GehQar7YeBy4Ftn7ZcCX0xyDfNn6pd1zb0UeGbYIiVJ/en7o5BVdayqXltVE1U1wXygv6Gq/go4COxK8uoklwPbgc+PtGJJ0rJ6+SjkncBngR9LcjzJTUvNrapHgLuAR4HPAO+pqpdHVawkqTfLXpapqncvMz6xYPkW4JbhypIkDcNvqEpSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkN6uUfyP5wklNJHu5a95+SfDnJl5J8IslFXWM3J3kyyeNJ3rJCdUuSvoteztw/Aly3YN19wFVV9TrgK8DNAEmuAHYBV3a2uT3JeSOrVpLUk2XDvaruB76+YN0fVdWZzuIDwKWdxzuBmap6qaq+CjwJXDPCeiVJPUhVLT8pmQA+WVVXLTL2P4Dfr6qPJvkg8EBVfbQzdgfw6aq6e5Ht9gB7AMbHx6+emZk5OzY3N8fY2NhgHa1DG6lfe23Xeu732InTfc0f3wwnXxzNsXdsu3Dgbaenp49W1eRiY5sG3iuQ5LeAM8DHvrVqkWmLvnpU1X5gP8Dk5GRNTU2dHZudnaV7uXUbqV97bdd67vfGfYf6mr93xxluOzZUfJ711A1TI9nPQgNXl2Q38Hbg2vr26f9x4LKuaZcCzwxeniRpEAN9FDLJdcBvAu+oqv/XNXQQ2JXk1UkuB7YDnx++TElSP5Y9c09yJzAFbElyHPgA85+OeTVwXxKYv87+q1X1SJK7gEeZv1zznqp6eaWKlyQtbtlwr6p3L7L6ju8y/xbglmGKkiQNx2+oSlKDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ1aNtyTfDjJqSQPd627JMl9SZ7o/Ly4a+zmJE8meTzJW1aqcEnS0no5c/8IcN2CdfuAw1W1HTjcWSbJFcAu4MrONrcnOW9k1UqSerJsuFfV/cDXF6zeCRzoPD4AXN+1fqaqXqqqrwJPAteMplRJUq9SVctPSiaAT1bVVZ3l56vqoq7x56rq4iQfBB6oqo921t8BfLqq7l5kn3uAPQDj4+NXz8zMnB2bm5tjbGxsmL7WlY3Ur722az33e+zE6b7mj2+Gky+O5tg7tl048LbT09NHq2pysbFNA+91cVlk3aKvHlW1H9gPMDk5WVNTU2fHZmdn6V5u3Ubq117btZ77vXHfob7m791xhtuOjSY+n7phaiT7WWjQT8ucTLIVoPPzVGf9ceCyrnmXAs8MXp4kaRCDhvtBYHfn8W7g3q71u5K8OsnlwHbg88OVKEnq17K/VyS5E5gCtiQ5DnwAuBW4K8lNwNPAuwCq6pEkdwGPAmeA91TVyytUuyRpCcuGe1W9e4mha5eYfwtwyzBFSZKG4zdUJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1aKhwT/JvkjyS5OEkdyb5niSXJLkvyROdnxePqlhJUm8GDvck24DfACar6irgPGAXsA84XFXbgcOdZUnSKhr2sswmYHOSTcBrgGeAncCBzvgB4PohjyFJ6tPA4V5VJ4D/DDwNPAucrqo/Asar6tnOnGeB146iUElS71JVg204fy3948AvAs8DfwDcDXywqi7qmvdcVb3iunuSPcAegPHx8atnZmbOjs3NzTE2NjZQXevRRurXXtu1nvs9duJ0X/PHN8PJF0dz7B3bLhx42+np6aNVNbnY2KaB9wo/B3y1qv4vQJJ7gDcCJ5Nsrapnk2wFTi22cVXtB/YDTE5O1tTU1Nmx2dlZupdbt5H6tdd2red+b9x3qK/5e3ec4bZjw8Tntz11w9RI9rPQMNfcnwZ+OslrkgS4FngMOAjs7szZDdw7XImSpH4N/NJTVZ9LcjfwReAM8GfMn4mPAXcluYn5F4B3jaJQSVLvhvq9oqo+AHxgweqXmD+LlyStEb+hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDVoqHBPclGSu5N8OcljSX4mySVJ7kvyROfnxaMqVpLUm2HP3H8H+ExV/TjweuAxYB9wuKq2A4c7y5KkVTRwuCe5APhZ4A6AqvpmVT0P7AQOdKYdAK4frkRJUr9SVYNtmPwksB94lPmz9qPA+4ATVXVR17znquoVl2aS7AH2AIyPj189MzNzdmxubo6xsbGB6lqPNlK/9tqu9dzvsROn+5o/vhlOvjiaY+/YduHA205PTx+tqsnFxoYJ90ngAeBNVfW5JL8DfAN4by/h3m1ycrKOHDlydnl2dpapqamB6lqPNlK/9tqu9dzvxL5Dfc3fu+MMtx3bNJJjP3Xr2wbeNsmS4T7MNffjwPGq+lxn+W7gDcDJJFs7B94KnBriGJKkAQwc7lX1V8BfJvmxzqprmb9EcxDY3Vm3G7h3qAolSX0b9veK9wIfS/Iq4M+Bf878C8ZdSW4CngbeNeQxJEl9Gircq+pBYLHrPdcOs19J0nD8hqokNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoKHDPcl5Sf4sySc7y5ckuS/JE52fFw9fpiSpH6M4c38f8FjX8j7gcFVtBw53liVJq2iocE9yKfA24ENdq3cCBzqPDwDXD3MMSVL/UlWDb5zcDfwH4HuB91fV25M8X1UXdc15rqpecWkmyR5gD8D4+PjVMzMzZ8fm5uYYGxsbuK71ZiP1a6/tWs/9Hjtxuq/545vh5IujOfaObRcOvO309PTRqppcbGzToDtN8nbgVFUdTTLV7/ZVtR/YDzA5OVlTU9/exezsLN3LrdtI/dpru9ZzvzfuO9TX/L07znDbsYHj8zs8dcPUSPaz0DDVvQl4R5K3At8DXJDko8DJJFur6tkkW4FToyhUktS7ga+5V9XNVXVpVU0Au4A/rqp/BhwEdnem7QbuHbpKSVJfVuJz7rcCb07yBPDmzrIkaRWN5KJRVc0Cs53Hfw1cO4r9SpIG4zdUJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYNHO5JLkvyv5I8luSRJO/rrL8kyX1Jnuj8vHh05UqSejHMmfsZYG9V/QTw08B7klwB7AMOV9V24HBnWZK0igYO96p6tqq+2Hn8N8BjwDZgJ3CgM+0AcP2QNUqS+pSqGn4nyQRwP3AV8HRVXdQ19lxVveLSTJI9wB6A8fHxq2dmZs6Ozc3NMTY2NnRd68VG6tde27We+z124nRf88c3w8kXR3PsHdsuHHjb6enpo1U1udjY0OGeZAz4E+CWqronyfO9hHu3ycnJOnLkyNnl2dlZpqamhqprPdlI/dpru9ZzvxP7DvU1f++OM9x2bNNIjv3UrW8beNskS4b7UJ+WSfL3gY8DH6uqezqrTybZ2hnfCpwa5hiSpP4N82mZAHcAj1XVf+kaOgjs7jzeDdw7eHmSpEEM83vFm4BfBo4lebCz7t8BtwJ3JbkJeBp411AVSpL6NnC4V9X/BrLE8LWD7leSNLzRvCOwxvp9M2RUhnkjRJJWkrcfkKQGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoBUL9yTXJXk8yZNJ9q3UcSRJr7Qi/4ZqkvOA3wXeDBwHvpDkYFU9uhLHk9SGtfr3kFu0Umfu1wBPVtWfV9U3gRlg5wodS5K0wIqcuQPbgL/sWj4O/MPuCUn2AHs6i3NJHu8a3gJ8bYVqG5n8x5Htal30OyL22q4N0+9vjLDXIXPkB5caWKlwzyLr6jsWqvYD+xfdODlSVZMrUdi5aCP1a6/t2kj9rodeV+qyzHHgsq7lS4FnVuhYkqQFVircvwBsT3J5klcBu4CDK3QsSdICK3JZpqrOJPlXwP8EzgM+XFWP9LGLRS/XNGwj9Wuv7dpI/Z7zvaaqlp8lSVpX/IaqJDXIcJekBq1puC93i4IkP57ks0leSvL+tahxVHro9YYkX+r8+dMkr1+LOkelh353dnp9MMmRJP9oLeochV5vtZHkp5K8nOSdq1nfKPXwvE4lOd15Xh9M8ttrUeco9PK8dvp9MMkjSf5ktWv8rqpqTf4w/0br/wF+CHgV8BBwxYI5rwV+CrgFeP9a1bpKvb4RuLjz+OeBz6113Svc7xjffs/ndcCX17ruleq1a94fA58C3rnWda/g8zoFfHKta12lXi8CHgV+oLP82rWuu/vPWp65L3uLgqo6VVVfAP52LQocoV56/dOqeq6z+ADz3w1Yr3rpd646fyOA81nwJbd1pNdbbbwX+DhwajWLG7GNdFuRXnr9JeCeqnoa5vNqlWv8rtYy3Be7RcG2NaplpfXb603Ap1e0opXVU79JfiHJl4FDwL9YpdpGbdlek2wDfgH4vVWsayX0+v/xzyR5KMmnk1y5OqWNXC+9/ihwcZLZJEeT/MqqVdeDlbr9QC+WvUVBQ3ruNck08+G+bq9B02O/VfUJ4BNJfhb498DPrXRhK6CXXv8b8JtV9XKy2PR1o5devwj8YFXNJXkr8IfA9pUubAX00usm4GrgWmAz8NkkD1TVV1a6uF6sZbhvpFsU9NRrktcBHwJ+vqr+epVqWwl9PbdVdX+SH06yparW242neul1EpjpBPsW4K1JzlTVH65KhaOzbK9V9Y2ux59KcnvDz+tx4GtV9QLwQpL7gdcD50S4r+VlmY10i4Jle03yA8A9wC+fK6/8Q+il3x9JJ+2SvIH5N63W4wvasr1W1eVVNVFVE8DdwK+vw2CH3p7X7+96Xq9hPmOafF6Be4F/nGRTktcwf+fbx1a5ziWt2Zl7LXGLgiS/2hn/vSTfDxwBLgD+Lsm/Zv4d628std9zUS+9Ar8NfB9we+fvxpk6x+86t5Qe+/2nwK8k+VvgReAXu95gXTd67LUJPfb6TuDXkpxh/nnd1erzWlWPJfkM8CXg74APVdXDa1f1d/L2A5LUIL+hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSg/4/oczzq69+DXEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_plot = pd.DataFrame(y_pred)\n",
    "y_pred_plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78f801bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = (y_pred_plot > 0.5) *1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "378c6645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of: 0.6325301204819277\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_test, cutoff, labels=[0, 1,])\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "\n",
    "print('Accuracy score of:' ,accuracy_score(y_test, cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9341e475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.16      0.27        67\n",
      "           1       0.63      0.95      0.76        99\n",
      "\n",
      "    accuracy                           0.63       166\n",
      "   macro avg       0.66      0.56      0.51       166\n",
      "weighted avg       0.65      0.63      0.56       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0','1']\n",
    "print(classification_report(y_test, cutoff, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "811754c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18897777282804024"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(y_test, cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11323706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0332ee06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e89f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
